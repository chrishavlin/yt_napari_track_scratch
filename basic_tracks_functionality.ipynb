{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6caac0a-ca39-433b-8450-f9f76aaa57fb",
   "metadata": {},
   "source": [
    "using the napari tracks layers : https://napari.org/stable/howtos/layers/tracks.html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "294e0e31-9e70-485f-bb86-e552d1bb5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2b8ae0-6914-41cf-9768-3fcd6e6a5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f925714-5950-416c-8fc7-b866510d6c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1182e243-405d-4002-a9a5-b832573e47fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_tracks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtail_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtail_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhead_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtranslate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrotate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maffine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mopacity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mblending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'additive'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolormap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'turbo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolor_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'track_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolormaps_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexperimental_clipping_planes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnapari\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTracks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Add a Tracks layer to the layer list. \n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data : array (N, D+1)\n",
       "    Coordinates for N points in D+1 dimensions. ID,T,(Z),Y,X. The first\n",
       "    axis is the integer ID of the track. D is either 3 or 4 for planar\n",
       "    or volumetric timeseries respectively.\n",
       "features : Dataframe-like\n",
       "    Features table where each row corresponds to a point and each column\n",
       "    is a feature.\n",
       "properties : dict {str: array (N,)}, DataFrame\n",
       "    Properties for each point. Each property should be an array of length N,\n",
       "    where N is the number of points.\n",
       "graph : dict {int: list}\n",
       "    Graph representing associations between tracks. Dictionary defines the\n",
       "    mapping between a track ID and the parents of the track. This can be\n",
       "    one (the track has one parent, and the parent has >=1 child) in the\n",
       "    case of track splitting, or more than one (the track has multiple\n",
       "    parents, but only one child) in the case of track merging.\n",
       "    See examples/tracks_3d_with_graph.py\n",
       "color_by : str\n",
       "    Track property (from property keys) by which to color vertices.\n",
       "tail_width : float\n",
       "    Width of the track tails in pixels.\n",
       "tail_length : float\n",
       "    Length of the positive (backward in time) tails in units of time.\n",
       "head_length : float\n",
       "    Length of the positive (forward in time) tails in units of time.\n",
       "colormap : str\n",
       "    Default colormap to use to set vertex colors. Specialized colormaps,\n",
       "    relating to specified properties can be passed to the layer via\n",
       "    colormaps_dict.\n",
       "colormaps_dict : dict {str: napari.utils.Colormap}\n",
       "    Optional dictionary mapping each property to a colormap for that\n",
       "    property. This allows each property to be assigned a specific colormap,\n",
       "    rather than having a global colormap for everything.\n",
       "name : str\n",
       "    Name of the layer.\n",
       "metadata : dict\n",
       "    Layer metadata.\n",
       "scale : tuple of float\n",
       "    Scale factors for the layer.\n",
       "translate : tuple of float\n",
       "    Translation values for the layer.\n",
       "rotate : float, 3-tuple of float, or n-D array.\n",
       "    If a float convert into a 2D rotation matrix using that value as an\n",
       "    angle. If 3-tuple convert into a 3D rotation matrix, using a yaw,\n",
       "    pitch, roll convention. Otherwise assume an nD rotation. Angles are\n",
       "    assumed to be in degrees. They can be converted from radians with\n",
       "    np.degrees if needed.\n",
       "shear : 1-D array or n-D array\n",
       "    Either a vector of upper triangular values, or an nD shear matrix with\n",
       "    ones along the main diagonal.\n",
       "affine : n-D array or napari.utils.transforms.Affine\n",
       "    (N+1, N+1) affine transformation matrix in homogeneous coordinates.\n",
       "    The first (N, N) entries correspond to a linear transform and\n",
       "    the final column is a length N translation vector and a 1 or a napari\n",
       "    `Affine` transform object. Applied as an extra transform on top of the\n",
       "    provided scale, rotate, and shear values.\n",
       "opacity : float\n",
       "    Opacity of the layer visual, between 0.0 and 1.0.\n",
       "blending : str\n",
       "    One of a list of preset blending modes that determines how RGB and\n",
       "    alpha values of the layer visual get mixed. Allowed values are\n",
       "    {'opaque', 'translucent', and 'additive'}.\n",
       "visible : bool\n",
       "    Whether the layer visual is currently being displayed.\n",
       "cache : bool\n",
       "    Whether slices of out-of-core datasets should be cached upon retrieval.\n",
       "    Currently, this only applies to dask arrays.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "layer : :class:`napari.layers.Tracks`\n",
       "    The newly-created tracks layer.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.pyenv/versions/3.10.11/envs/yt-napari/lib/python3.10/site-packages/napari/components/viewer_model.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v.add_tracks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a201f1-0706-4973-a4f0-8f8add99d611",
   "metadata": {},
   "source": [
    "## biased random walk \n",
    "\n",
    "The following function takes a fixed number of particles and projects forward in time using a biased random walk. At each timestep, the trajectory is a weighted average of the previous timestep's trajectory with a new trajectory (of random orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f3af0d4-2e27-442d-877e-a58a70b8c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def biased_random_walk_tracks(n_particles, n_timesteps, image_size_xyz, bias_old = 0.8):    \n",
    "    # random walk with biases towards trajectory from prior timestep. particles are \n",
    "    # individual and persistent \n",
    "    track_data = []\n",
    "    ids = np.arange(n_particles, dtype='int').transpose()\n",
    "    \n",
    "    # initialize start positions     \n",
    "    xyz = np.random.random((n_particles, 3))\n",
    "    t = np.zeros((n_particles,))\n",
    "\n",
    "    # track array columns: ID,T,(Z),Y,X\n",
    "    current_track = np.column_stack([ids, t, xyz[:, 2], xyz[:, 1], xyz[:, 0]])\n",
    "    track_data.append(current_track)      \n",
    "    \n",
    "    for it in range(n_timesteps):\n",
    "        d_xyz = (np.random.random((n_particles, 3)) - 0.5) * 0.1\n",
    "\n",
    "        if it > 0:\n",
    "            d_xyz = d_xyz0 * bias_old + d_xyz * (1 - bias_old)\n",
    "        \n",
    "        xyz = xyz + d_xyz \n",
    "        t = t + 1 # arbitrary time\n",
    "        current_track = np.column_stack([ids, t, xyz[:, 2], xyz[:, 1], xyz[:, 0]])\n",
    "        track_data.append(current_track)\n",
    "        \n",
    "        d_xyz0 = d_xyz\n",
    "\n",
    "    track_data = np.concatenate(track_data)\n",
    "\n",
    "    # scale final position ranges\n",
    "    for idim in range(3): \n",
    "        mx_dim = track_data[:, idim+2].max()\n",
    "        mn_dim = track_data[:, idim+2].min()\n",
    "        scaled = (track_data[:, idim+2] - mn_dim)/ (mx_dim - mn_dim)\n",
    "        track_data[:, idim+2] = scaled * image_size_xyz[idim]\n",
    "\n",
    "    track_data = track_data[track_data[:, 0].argsort()]#.astype('int')\n",
    "    \n",
    "    return track_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ebd8373-c3c5-4b01-b5a2-524503ccd6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10050, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_particles = 50\n",
    "timesteps = 200\n",
    "tracks = biased_random_walk_tracks(n_particles, timesteps, (400, 400, 400))\n",
    "tracks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80520b8-4cc9-4a1b-8339-50b9f125f83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6424e410-bbea-44e3-b11d-7d5653681dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tracks layer 'tracks' at 0x2bc7dbc40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.add_tracks(tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a900b78-1ec2-4e0d-bfdb-dbab3fdabb0e",
   "metadata": {},
   "source": [
    "notes on viewing in napari:\n",
    "\n",
    "in 2D view, all tracks are projected to the 2d plane (https://github.com/napari/napari/issues/3861)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec4cfd-59d8-4142-b1d5-0d434c848fda",
   "metadata": {},
   "source": [
    "## biased random walk with particle generation \n",
    "\n",
    "Same as before, but now there's a nonzero chance of each particle spawning a new particle. The new particle starts with the same position and old trajectory (which will be weighted with a new, different trajectory)\n",
    "\n",
    "Still just using `np.random.random`.... a new particle is generated if `np.random.random() < gen_particle_coeff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "219898dc-1818-419b-936d-ce208c17aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def biased_random_walk_tracks_with_generation(n_starting, \n",
    "                                              n_max_particles, \n",
    "                                              n_timesteps, \n",
    "                                              image_size_xyz, \n",
    "                                              bias_old = 0.8,\n",
    "                                              gen_particle_coeff=0.05):    \n",
    "    # random walk with biases towards trajectory from prior timestep. particles are \n",
    "    # individual and persistent \n",
    "    track_data = []\n",
    "    \n",
    "    # initialize start positions     \n",
    "    xyz = np.random.random((n_starting, 3))\n",
    "    t = np.zeros((n_starting,))\n",
    "    ids = np.arange(n_starting, dtype='int').transpose()\n",
    "\n",
    "    # track array columns: ID,T,(Z),Y,X\n",
    "    current_track = np.column_stack([ids, t, xyz[:, 2], xyz[:, 1], xyz[:, 0]])\n",
    "    track_data.append(current_track)\n",
    "\n",
    "    n_particles = n_starting\n",
    "    graph = {}\n",
    "    for it in range(n_timesteps):\n",
    "\n",
    "        # particle generation\n",
    "        generate_draw = np.random.random((n_particles,)) < gen_particle_coeff\n",
    "        n_new_particles = np.sum(generate_draw)\n",
    "        \n",
    "        if n_new_particles  > 0 and n_particles < n_max_particles:\n",
    "            # graph : dict {int: list}\n",
    "            # Graph representing associations between tracks. Dictionary defines the\n",
    "            # mapping between a track ID and the parents of the track. This can be\n",
    "            # one (the track has one parent, and the parent has >=1 child) in the\n",
    "            # case of track splitting, or more than one (the track has multiple\n",
    "            # parents, but only one child) in the case of track merging.\n",
    "            # See examples/tracks_3d_with_graph.py\n",
    "            parent_ids = ids[generate_draw]\n",
    "            new_ids = np.arange(len(ids), len(ids)+n_new_particles, dtype='int').transpose()\n",
    "            for id, parent_id in zip(new_ids, parent_ids):\n",
    "                # child points to parent\n",
    "                graph[id] = parent_id\n",
    "                            \n",
    "            ids = np.concatenate([ids, new_ids])\n",
    "            xyz = np.concatenate([xyz, xyz[generate_draw]])            \n",
    "            t = np.concatenate([t, t[generate_draw]])                        \n",
    "            n_particles = len(ids)\n",
    "            if it > 0: \n",
    "                d_xyz0 = np.concatenate([d_xyz0, d_xyz0[generate_draw]])\n",
    "            \n",
    "        \n",
    "        d_xyz = (np.random.random((n_particles, 3)) - 0.5) * 0.1\n",
    "\n",
    "        if it > 0:\n",
    "            d_xyz = d_xyz0 * bias_old + d_xyz * (1 - bias_old)\n",
    "        \n",
    "        xyz = xyz + d_xyz \n",
    "        t = t + 1 # arbitrary time\n",
    "        current_track = np.column_stack([ids, t, xyz[:, 2], xyz[:, 1], xyz[:, 0]])\n",
    "        track_data.append(current_track)\n",
    "        \n",
    "        d_xyz0 = d_xyz\n",
    "\n",
    "    track_data = np.concatenate(track_data)\n",
    "\n",
    "    # scale final position ranges\n",
    "    for idim in range(3): \n",
    "        mx_dim = track_data[:, idim+2].max()\n",
    "        mn_dim = track_data[:, idim+2].min()\n",
    "        scaled = (track_data[:, idim+2] - mn_dim)/ (mx_dim - mn_dim)\n",
    "        track_data[:, idim+2] = scaled * image_size_xyz[idim]\n",
    "\n",
    "    track_data = track_data[track_data[:, 0].argsort()]#.astype('int')\n",
    "    \n",
    "    return track_data, graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aac942c-c4dc-418c-a7b7-517d0b3cd3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6742, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_particles = 2\n",
    "n_max_particles = 100\n",
    "timesteps = 200\n",
    "tracks, graph = biased_random_walk_tracks_with_generation(n_particles, \n",
    "                                                   n_max_particles,\n",
    "                                                   timesteps, \n",
    "                                                   (400, 400, 400), \n",
    "                                                    gen_particle_coeff=0.03,\n",
    "                                                    )\n",
    "tracks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a14f85fa-e770-42af-adef-bcccb98f98fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.layers.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a131204b-ef81-45fa-861b-75fc2f229c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tracks layer 'tracks' at 0x2b5c46770>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: skipping QEventPoint(id=1 ts=0 pos=0,0 scn=574.464,653.023 gbl=574.464,653.023 Released ellipse=(1x1 ∡ 0) vel=0,0 press=-574.464,-653.023 last=-574.464,-653.023 Δ 574.464,653.023) : no target window\n",
      "WARNING: skipping QEventPoint(id=1 ts=0 pos=0,0 scn=522.021,725.985 gbl=522.021,725.985 Released ellipse=(1x1 ∡ 0) vel=0,0 press=-522.021,-725.985 last=-522.021,-725.985 Δ 522.021,725.985) : no target window\n",
      "WARNING: skipping QEventPoint(id=1 ts=0 pos=0,0 scn=671.135,654.594 gbl=671.135,654.594 Released ellipse=(1x1 ∡ 0) vel=0,0 press=-671.135,-654.594 last=-671.135,-654.594 Δ 671.135,654.594) : no target window\n",
      "WARNING: skipping QEventPoint(id=1 ts=0 pos=0,0 scn=443.031,740.338 gbl=443.031,740.338 Released ellipse=(1x1 ∡ 0) vel=0,0 press=-443.031,-740.338 last=-443.031,-740.338 Δ 443.031,740.338) : no target window\n",
      "WARNING: skipping QEventPoint(id=1 ts=0 pos=0,0 scn=627.449,462.954 gbl=627.449,462.954 Released ellipse=(1x1 ∡ 0) vel=0,0 press=-627.449,-462.954 last=-627.449,-462.954 Δ 627.449,462.954) : no target window\n",
      "WARNING: skipping QEventPoint(id=1 ts=0 pos=0,0 scn=309.904,617.456 gbl=309.904,617.456 Released ellipse=(1x1 ∡ 0) vel=0,0 press=-309.904,-617.456 last=-309.904,-617.456 Δ 309.904,617.456) : no target window\n",
      "WARNING: skipping QEventPoint(id=1 ts=0 pos=0,0 scn=380.044,670.936 gbl=380.044,670.936 Released ellipse=(1x1 ∡ 0) vel=0,0 press=-380.044,-670.936 last=-380.044,-670.936 Δ 380.044,670.936) : no target window\n",
      "WARNING: skipping QEventPoint(id=1 ts=0 pos=0,0 scn=472.275,504.827 gbl=472.275,504.827 Released ellipse=(1x1 ∡ 0) vel=0,0 press=-472.275,-504.827 last=-472.275,-504.827 Δ 472.275,504.827) : no target window\n",
      "WARNING: skipping QEventPoint(id=1 ts=0 pos=0,0 scn=327.567,702.741 gbl=327.567,702.741 Released ellipse=(1x1 ∡ 0) vel=0,0 press=-327.567,-702.741 last=-327.567,-702.741 Δ 327.567,702.741) : no target window\n",
      "WARNING: skipping QEventPoint(id=1 ts=0 pos=0,0 scn=366.076,612.598 gbl=366.076,612.598 Released ellipse=(1x1 ∡ 0) vel=0,0 press=-366.076,-612.598 last=-366.076,-612.598 Δ 366.076,612.598) : no target window\n",
      "WARNING: skipping QEventPoint(id=1 ts=0 pos=0,0 scn=325.38,723.09 gbl=325.38,723.09 Released ellipse=(1x1 ∡ 0) vel=0,0 press=-325.38,-723.09 last=-325.38,-723.09 Δ 325.38,723.09) : no target window\n",
      "WARNING: skipping QEventPoint(id=1 ts=0 pos=0,0 scn=701.852,470.846 gbl=701.852,470.846 Released ellipse=(1x1 ∡ 0) vel=0,0 press=-701.852,-470.846 last=-701.852,-470.846 Δ 701.852,470.846) : no target window\n"
     ]
    }
   ],
   "source": [
    "v.add_tracks(tracks, graph=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a36a3d-5446-4deb-a024-dabb608deb83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
